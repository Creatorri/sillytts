{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6LWsNd3_M3MP"
   },
   "source": [
    "# Mozilla TTS on CPU Real-Time Speech Synthesis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FAqrSIWgLyP0"
   },
   "source": [
    "We use Tacotron2 and MultiBand-Melgan models and LJSpeech dataset.\n",
    "\n",
    "Tacotron2 is trained using [Double Decoder Consistency](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/) (DDC) only for 130K steps (3 days) with a single GPU.\n",
    "\n",
    "MultiBand-Melgan is trained  1.45M steps with real spectrograms.\n",
    "\n",
    "Note that both model performances can be improved with more training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ku-dA4DKoeXk"
   },
   "source": [
    "### Download Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "jGIgnWhGsxU1",
    "outputId": "479415d4-d51f-479a-9d7a-942f86827844"
   },
   "outputs": [],
   "source": [
    "#!gdown --id 1dntzjWFg7ufWaTaFy80nRz-Tu02xWZos -O tts_model.pth.tar\n",
    "#!gdown --id 18CQ6G6tBEOfvCHlPqP8EBI4xWbrr9dBc -O config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "4dnpE0-kvTsu",
    "outputId": "6c63ba9e-4c76-441b-b09a-c5bb739da5a6"
   },
   "outputs": [],
   "source": [
    "#!gdown --id 1Ty5DZdOc0F7OTGj9oJThYbL5iVu_2G0K -O vocoder_model.pth.tar\n",
    "#!gdown --id 1Rd0R_nRCrbjEdpOwq6XwZAktvugiBvmu -O config_vocoder.json\n",
    "#!gdown --id 11oY3Tv0kQtxK_JPgxrfesa99maVXHNxU -O scale_stats.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ZuDrj_ioqHE"
   },
   "source": [
    "### Setup Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "colab_type": "code",
    "id": "X2axt5BYq7gv",
    "outputId": "be7a2789-2117-4c2d-a36e-d1898b801c64"
   },
   "outputs": [],
   "source": [
    "#!sudo apt-get install espeak ffmpeg -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "ZduAf-qYYEIT",
    "outputId": "a713c901-caa5-415d-bdfc-157111693438"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/mozilla/TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ofPCvPyjZEcT",
    "outputId": "72fae728-af17-4dab-a519-0a9bca31df9c"
   },
   "outputs": [],
   "source": [
    "#%cd TTS\n",
    "#!git checkout b1935c97\n",
    "#!pip install -r requirements.txt\n",
    "#!python setup.py install\n",
    "#!pip install inflect pydub\n",
    "#%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZksegYQepkFg"
   },
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oVa0kOamprgj"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import copy\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import IPython\n",
    "import numpy as np\n",
    "import scipy.io.wavfile\n",
    "import math\n",
    "#from playsound import playsound\n",
    "\n",
    "from TTS.utils.generic_utils import setup_model\n",
    "from TTS.utils.io import load_config\n",
    "from TTS.utils.text.symbols import symbols, phonemes\n",
    "from TTS.utils.audio import AudioProcessor\n",
    "from TTS.utils.synthesis import synthesis\n",
    "from TTS.vocoder.utils.generic_utils import setup_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NqazAJEhvK_U"
   },
   "outputs": [],
   "source": [
    "import resource\n",
    "#TTS Class\n",
    "class TTSModel:\n",
    "    def __init__(self, TTS_MODEL, TTS_CONFIG, VOCODER_MODEL, VOCODER_CONFIG, use_cuda, use_gl):\n",
    "        self.use_cuda = use_cuda\n",
    "        self.use_gl = use_gl \n",
    "        # model paths\n",
    "        self.tts_config = load_config(TTS_CONFIG)\n",
    "        vocoder_config = load_config(VOCODER_CONFIG)\n",
    "        # load audio processor\n",
    "        self.ap = AudioProcessor(**self.tts_config.audio)\n",
    "        # LOAD TTS MODEL\n",
    "        # multi speaker \n",
    "        self.speaker_id = None\n",
    "        speakers = []\n",
    "        # load the model\n",
    "        num_chars = len(phonemes) if self.tts_config.use_phonemes else len(symbols)\n",
    "        self.model = setup_model(num_chars, len(speakers), self.tts_config)\n",
    "        # load model state\n",
    "        self.cp =  torch.load(TTS_MODEL, map_location=torch.device('cpu'))\n",
    "        # load the model\n",
    "        self.model.load_state_dict(self.cp['model'])\n",
    "        if self.use_cuda:\n",
    "            self.model.cuda()\n",
    "        self.model.eval()\n",
    "        # set model stepsize\n",
    "        if 'r' in self.cp:\n",
    "            self.model.decoder.set_r(self.cp['r'])\n",
    "        # LOAD VOCODER MODEL\n",
    "        self.vocoder_model = setup_generator(vocoder_config)\n",
    "        self.vocoder_model.load_state_dict(torch.load(VOCODER_MODEL, map_location=\"cpu\")[\"model\"])\n",
    "        self.vocoder_model.remove_weight_norm()\n",
    "        self.vocoder_model.inference_padding = 0\n",
    "        #ap_vocoder = AudioProcessor(**vocoder_config['audio'])    \n",
    "        if use_cuda:\n",
    "            self.vocoder_model.cuda()\n",
    "        self.vocoder_model.eval()\n",
    "        #get sample rate\n",
    "        self.sample_rate = self.ap.sample_rate\n",
    "        gc.collect(2)\n",
    "    def tts(self,text,interactive=False,printable=False):\n",
    "        figures=True\n",
    "        t_1 = time.time()\n",
    "        tmodel = copy.deepcopy(self.model)\n",
    "        #tvoc = copy.deepcopy(self.vocoder_model)\n",
    "        \n",
    "        enable_chars = self.tts_config.enable_eos_bos_chars\n",
    "        waveform, alignment, mel_spec, mel_postnet_spec, stop_tokens, inputs = synthesis(tmodel, text, self.tts_config, self.use_cuda, self.ap, self.speaker_id, style_wav=None, truncated=False, enable_eos_bos_chars=enable_chars)\n",
    "        # mel_postnet_spec = ap._denormalize(mel_postnet_spec.T)\n",
    "        del tmodel\n",
    "        gc.collect(2)\n",
    "        \n",
    "        if not self.use_gl:\n",
    "            waveform = self.vocoder_model.inference(torch.FloatTensor(mel_postnet_spec.T).unsqueeze(0))\n",
    "            waveform = waveform.flatten()\n",
    "        if self.use_cuda:\n",
    "            waveform = waveform.cpu()\n",
    "        else:\n",
    "            waveform = waveform.numpy()\n",
    "        #del tvoc\n",
    "        \n",
    "        if printable:\n",
    "          rtf = (time.time() - t_1) / (len(waveform) / self.ap.sample_rate)\n",
    "          tps = (time.time() - t_1) / len(waveform)\n",
    "          usage = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
    "          print(waveform.shape)\n",
    "          print(\" > Run-time: {}\".format(time.time() - t_1))\n",
    "          print(\" > Memory Used: {} MB\".format(math.floor(usage/1024))) \n",
    "          print(\" > Real-time factor: {}\".format(rtf))\n",
    "          print(\" > Time per step: {}\".format(tps))\n",
    "        if interactive:\n",
    "            IPython.display.display(IPython.display.Audio(waveform, rate=self.sample_rate)) \n",
    "        gc.collect(2)\n",
    "        return alignment, mel_postnet_spec, stop_tokens, waveform\n",
    "    def simpletts(self,text):\n",
    "        _,_,_,wav = self.tts(text)\n",
    "        return wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ws_YkPKsLgo-"
   },
   "source": [
    "## See it in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bsVfOid6vK_a"
   },
   "outputs": [],
   "source": [
    "def tryit(sample):\n",
    "    # load the model\n",
    "    ttsmodel = TTSModel(\"tts_model.pth.tar\",\"config.json\",\"vocoder_model.pth.tar\",\"config_vocoder.json\",False,False)\n",
    "    # input sample and hear it!\n",
    "    stuff = ttsmodel.tts(sample,True)\n",
    "    del stuff\n",
    "    del ttsmodel\n",
    "#tryit(\"Bill got in the habit of asking himself “Is that thought true?” and if he wasn’t absolutely certain it was, he just let it go.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0C6vEzK-vK_g"
   },
   "source": [
    "## Process files and output to wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6iZzmbp-vK_h"
   },
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from functools import reduce\n",
    "import re\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zQUNCrRfvK_m"
   },
   "outputs": [],
   "source": [
    "def preprocess(info):\n",
    "    info = ' '.join(info.split('\\n'))\n",
    "    info = info.replace('- ','')\n",
    "    into = '|'.join(map(lambda x: x, info.split('  ')))\n",
    "    info = '|'.join(map(lambda x: x+'?', info.split('? ')))\n",
    "    info = '|'.join(map(lambda x: x+'.', info.split('. ')))\n",
    "    info = '|'.join(map(lambda x: x+'!', info.split('! ')))\n",
    "    info = info.split('|')\n",
    "    info = map(lambda x: ''.join(ch for ch in x if (ch.isalnum() or ch == ' ' or ch == '.' or ch == '?' or ch=='\"' or ch=='\\'' or ch=='”' or ch == '!')), info)\n",
    "    info = [x for x in info if re.search('[a-zA-Z]', x)]\n",
    "    #info = info[:-1]\n",
    "    return list(filter(lambda x: len(x)>1,info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h9yVS4hqvK_s"
   },
   "outputs": [],
   "source": [
    "def writetofile(sample_rate, name, wav):\n",
    "    scipy.io.wavfile.write(name,sample_rate,wav)\n",
    "    return\n",
    "def readfromfile(name):\n",
    "    (_, wav) = scipy.io.wavfile.read(name)\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_sents(wav1,wav2):\n",
    "    if not os.path.isfile('sil.wav'):\n",
    "        AudioSegment.silence(duration=800)\n",
    "    sil = readfromfile('sil.wav')\n",
    "    return np.concatenate((x,sil,y),axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import os.path\n",
    "\n",
    "def speaksents(ttsmodel, sents, out, workers):\n",
    "    def speak(sent):\n",
    "        return ttsmodel.simpletts(sent)\n",
    "    def nspeak(i):\n",
    "        print(i)\n",
    "        return ttsmodel.simpletts(sents[i])\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n",
    "        future = executor.map(speak, sents)\n",
    "        #future = executor.map(nspeak, range(len(sents)))\n",
    "        stuff = reduce(concat_sents,future)\n",
    "        del future\n",
    "        writetofile(ttsmodel.sample_rate, out+'.wav', stuff)\n",
    "        del stuff\n",
    "        gc.collect()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav2mp3(out):\n",
    "    Audiosegment.from_wav(out+'.wav').export(out+'.mp3',format='mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speaktofile(words,out,workers,ttsmodel):\n",
    "    t_0 = time.time()\n",
    "    initmodel = ttsmodel is None\n",
    "    if initmodel:\n",
    "        print('loading model')\n",
    "        ttsmodel = TTSModel(\"tts_model.pth.tar\",\"config.json\",\"vocoder_model.pth.tar\",\"config_vocoder.json\",False,False)\n",
    "    print('processing')\n",
    "    sents = preprocess(words)\n",
    "    print('reading '+str(len(sents))+' sentences')\n",
    "    t_1 = time.time()\n",
    "    speaksents(ttsmodel, sents, out, workers)\n",
    "    print('reading took '+str((time.time()-t_1)/(60*60))+' h')\n",
    "    if initmodel:\n",
    "        del ttsmodel\n",
    "    del sents\n",
    "    gc.collect(2)\n",
    "    print('converting to mp3')\n",
    "    wav2mp3(out)\n",
    "    print('done in '+str((time.time()-t_0)/(60*60))+' h')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readtofile(filename,out,workers=2,ttsmodel=None):\n",
    "    file = open(filename,\"r\")\n",
    "    words = file.read()\n",
    "    file.close()\n",
    "    speaktofile(words,out,workers,ttsmodel)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hdUCl56svLAB"
   },
   "source": [
    "## Run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c8P8aQP2L7HQ"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z16bKHW8vLAC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > num_mels:80\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:0\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:50.0\n",
      " | > mel_fmax:7600.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > stats_path:./scale_stats.npy\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Using model: Tacotron2\n",
      " > Generator Model: multiband_melgan_generator\n",
      "processing\n",
      "reading 225 sentences\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "readtofile(\"BeyondTheDoor.txt\",'beyond')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1kVIypcnvCeq"
   },
   "outputs": [],
   "source": [
    "#!cp \"HowWeBecame.wav\" \"gdrive/My Drive/\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MozillaTTS.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
