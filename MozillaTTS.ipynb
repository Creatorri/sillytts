{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6LWsNd3_M3MP"
   },
   "source": [
    "# Mozilla TTS on CPU Real-Time Speech Synthesis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FAqrSIWgLyP0"
   },
   "source": [
    "We use Tacotron2 and MultiBand-Melgan models and LJSpeech dataset.\n",
    "\n",
    "Tacotron2 is trained using [Double Decoder Consistency](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/) (DDC) only for 130K steps (3 days) with a single GPU.\n",
    "\n",
    "MultiBand-Melgan is trained  1.45M steps with real spectrograms.\n",
    "\n",
    "Note that both model performances can be improved with more training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ku-dA4DKoeXk"
   },
   "source": [
    "### Download Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "colab_type": "code",
    "id": "jGIgnWhGsxU1",
    "outputId": "88725e41-a8dc-4885-b3bf-cac939f38abe"
   },
   "outputs": [],
   "source": [
    "#!gdown --id 1dntzjWFg7ufWaTaFy80nRz-Tu02xWZos -O tts_model.pth.tar\n",
    "#!gdown --id 18CQ6G6tBEOfvCHlPqP8EBI4xWbrr9dBc -O config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "4dnpE0-kvTsu",
    "outputId": "76377c6d-789c-4995-ba00-a21a6e1c401e"
   },
   "outputs": [],
   "source": [
    "#!gdown --id 1Ty5DZdOc0F7OTGj9oJThYbL5iVu_2G0K -O vocoder_model.pth.tar\n",
    "#!gdown --id 1Rd0R_nRCrbjEdpOwq6XwZAktvugiBvmu -O config_vocoder.json\n",
    "#!gdown --id 11oY3Tv0kQtxK_JPgxrfesa99maVXHNxU -O scale_stats.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ZuDrj_ioqHE"
   },
   "source": [
    "### Setup Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "colab_type": "code",
    "id": "X2axt5BYq7gv",
    "outputId": "31762b5a-a3c6-416f-f80f-62f67b45fd48"
   },
   "outputs": [],
   "source": [
    "#! sudo apt-get install espeak ffmpeg -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ZduAf-qYYEIT",
    "outputId": "74159cf5-8505-4f63-9928-956f36b5bc54"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/mozilla/TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ofPCvPyjZEcT",
    "outputId": "bf450c54-ffe0-43e5-8acd-6003bed5fde5"
   },
   "outputs": [],
   "source": [
    "#%cd TTS\n",
    "#!git checkout b1935c97\n",
    "#!pip install -r requirements.txt\n",
    "#!python setup.py install\n",
    "#!pip install inflect pydub re\n",
    "#%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZksegYQepkFg"
   },
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oVa0kOamprgj"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import copy\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import IPython\n",
    "import numpy as np\n",
    "import scipy.io.wavfile\n",
    "import math\n",
    "from playsound import playsound\n",
    "\n",
    "from TTS.utils.generic_utils import setup_model\n",
    "from TTS.utils.io import load_config\n",
    "from TTS.utils.text.symbols import symbols, phonemes\n",
    "from TTS.utils.audio import AudioProcessor\n",
    "from TTS.utils.synthesis import synthesis\n",
    "from TTS.vocoder.utils.generic_utils import setup_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resource\n",
    "#TTS Class\n",
    "class TTSModel:\n",
    "    def __init__(self, TTS_MODEL, TTS_CONFIG, VOCODER_MODEL, VOCODER_CONFIG, use_cuda, use_gl):\n",
    "        self.use_cuda = use_cuda\n",
    "        self.use_gl = use_gl \n",
    "        # model paths\n",
    "        self.tts_config = load_config(TTS_CONFIG)\n",
    "        vocoder_config = load_config(VOCODER_CONFIG)\n",
    "        # load audio processor\n",
    "        self.ap = AudioProcessor(**self.tts_config.audio)\n",
    "        # LOAD TTS MODEL\n",
    "        # multi speaker \n",
    "        self.speaker_id = None\n",
    "        speakers = []\n",
    "        # load the model\n",
    "        num_chars = len(phonemes) if self.tts_config.use_phonemes else len(symbols)\n",
    "        self.model = setup_model(num_chars, len(speakers), self.tts_config)\n",
    "        # load model state\n",
    "        self.cp =  torch.load(TTS_MODEL, map_location=torch.device('cpu'))\n",
    "        # load the model\n",
    "        self.model.load_state_dict(self.cp['model'])\n",
    "        if self.use_cuda:\n",
    "            self.model.cuda()\n",
    "        self.model.eval()\n",
    "        # set model stepsize\n",
    "        if 'r' in self.cp:\n",
    "            self.model.decoder.set_r(self.cp['r'])\n",
    "        # LOAD VOCODER MODEL\n",
    "        self.vocoder_model = setup_generator(vocoder_config)\n",
    "        self.vocoder_model.load_state_dict(torch.load(VOCODER_MODEL, map_location=\"cpu\")[\"model\"])\n",
    "        self.vocoder_model.remove_weight_norm()\n",
    "        self.vocoder_model.inference_padding = 0\n",
    "        ap_vocoder = AudioProcessor(**vocoder_config['audio'])    \n",
    "        if use_cuda:\n",
    "            self.vocoder_model.cuda()\n",
    "        self.vocoder_model.eval()\n",
    "        #get sample rate\n",
    "        self.sample_rate = self.ap.sample_rate\n",
    "        gc.collect()\n",
    "    def tts(self,text,interactive=False):\n",
    "        figures=True\n",
    "        t_1 = time.time()\n",
    "        tmodel = copy.deepcopy(self.model)\n",
    "        #tmodel = self.model\n",
    "        tap = copy.deepcopy(self.ap)\n",
    "        #tap = self.ap\n",
    "        tvoc = copy.deepcopy(self.vocoder_model)\n",
    "        #tvoc = self.vocoder_model\n",
    "        enable_chars = self.tts_config.enable_eos_bos_chars\n",
    "        waveform, alignment, mel_spec, mel_postnet_spec, stop_tokens, inputs = synthesis(tmodel, text, self.tts_config, self.use_cuda, tap, \n",
    "                                                            self.speaker_id, style_wav=None, truncated=False, enable_eos_bos_chars=enable_chars)\n",
    "        # mel_postnet_spec = ap._denormalize(mel_postnet_spec.T)\n",
    "        del tmodel\n",
    "        del tap\n",
    "        gc.collect()\n",
    "        if not self.use_gl:\n",
    "            waveform = tvoc.inference(torch.FloatTensor(mel_postnet_spec.T).unsqueeze(0))\n",
    "            waveform = waveform.flatten()\n",
    "        if self.use_cuda:\n",
    "            waveform = waveform.cpu()\n",
    "        waveform = waveform.numpy()\n",
    "        del tvoc\n",
    "        #rtf = (time.time() - t_1) / (len(waveform) / self.ap.sample_rate)\n",
    "        #tps = (time.time() - t_1) / len(waveform)\n",
    "        #print(waveform.shape)\n",
    "        usage = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss \n",
    "        print(\" > Run-time: {}\".format(time.time() - t_1)) \n",
    "        print(\" > Memory Used: {} MB\".format(math.floor(usage/1024)))\n",
    "        #print(\" > Real-time factor: {}\".format(rtf))\n",
    "        #print(\" > Time per step: {}\".format(tps))\n",
    "        if interactive:\n",
    "            IPython.display.display(IPython.display.Audio(waveform, rate=self.sample_rate)) \n",
    "        gc.collect()\n",
    "        return alignment, mel_postnet_spec, stop_tokens, waveform\n",
    "    def simpletts(self,text):\n",
    "        a,m,s,wav = self.tts(text)\n",
    "        del a\n",
    "        del m\n",
    "        del s\n",
    "        gc.collect()\n",
    "        return wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ws_YkPKsLgo-"
   },
   "source": [
    "## See it in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tryit(sample):\n",
    "    # load the model\n",
    "    ttsmodel = TTSModel(\"tts_model.pth.tar\",\"config.json\",\"vocoder_model.pth.tar\",\"config_vocoder.json\",False,False)\n",
    "    # input sample and hear it!\n",
    "    stuff = ttsmodel.tts(sample,True)\n",
    "    del stuff\n",
    "    del ttsmodel\n",
    "#tryit(\"Bill got in the habit of asking himself “Is that thought true?” and if he wasn’t absolutely certain it was, he just let it go.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process files and output to wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from functools import reduce\n",
    "import re\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(info):\n",
    "    info = ' '.join(info.split('\\n'))\n",
    "    info = map(lambda x: x+'.', info.split('. '))\n",
    "    return list(filter(lambda x: len(x)>1,info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writetofile(sample_rate, name, wav):\n",
    "    scipy.io.wavfile.write(name,sample_rate,wav)\n",
    "    del wav\n",
    "    return\n",
    "def writesent(ttsmodel, name,sent):\n",
    "    scipy.io.wavfile.write(name,ttsmodel.sample_rate,ttsmodel.simpletts(sent))\n",
    "    gc.collect()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Separate speaking and acuumulating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speaksents(ttsmodel, sents):\n",
    "    for i in range(len(sents)):\n",
    "        print(i)\n",
    "        wav = ttsmodel.simpletts(sents[i])\n",
    "        writetofile(ttsmodel.sample_rate, 'tmp/thing'+str(i)+'.wav',wav)\n",
    "        del wav\n",
    "        gc.collect()\n",
    "    return\n",
    "def collectnonsense(num,out):\n",
    "    print(num)\n",
    "    copyfile(\"tmp/thing0.wav\",out)\n",
    "    os.remove(\"tmp/thing0.wav\")\n",
    "    for i in range(num-1):\n",
    "        thingi = \"tmp/thing\"+str(i+1)+\".wav\"\n",
    "        acc = AudioSegment.from_wav(out)\n",
    "        acc = acc + AudioSegment.from_wav(thingi)\n",
    "        acc.export(out,format=\"wav\")\n",
    "        del acc\n",
    "        os.remove(thingi)\n",
    "        gc.collect()\n",
    "    return\n",
    "def speaktofile(paragraphs,out):\n",
    "    print('loading model')\n",
    "    model = TTSModel(\"tts_model.pth.tar\",\"config.json\",\"vocoder_model.pth.tar\",\"config_vocoder.json\",False,False)\n",
    "    print('processing')\n",
    "    sents = preprocess(paragraphs)\n",
    "    #print(sents)\n",
    "    print('speaking')\n",
    "    speaksents(model, sents)\n",
    "    del model\n",
    "    print('collecting')\n",
    "    collectnonsense(len(sents),out)\n",
    "    print(\"Done!\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Speak and accumulate in the same step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accwavs(out,tmp):\n",
    "    gc.collect()\n",
    "    acc = AudioSegment.from_wav(out)\n",
    "    add = AudioSegment.from_wav(tmp)\n",
    "    acc = acc + add\n",
    "    del add\n",
    "    acc.export(out,format=\"wav\")\n",
    "    del acc\n",
    "    return\n",
    "def sillyspeak(ttsmodel, sents,out):\n",
    "    tmp = \"tmp/tmp.wav\"\n",
    "    writetofile(ttsmodel.sample_rate, out,ttsmodel.simpletts(sents[0]))\n",
    "    i = 0\n",
    "    for sent in sents[1:]:\n",
    "        tmpmodel = copy.copy(ttsmodel)\n",
    "        print(sent)\n",
    "        writesent(tmpmodel,tmp,sent)\n",
    "        del tmpmodel\n",
    "        gc.collect()\n",
    "        accwavs(out,tmp)\n",
    "        os.remove(tmp)\n",
    "        i += 1\n",
    "        print(i)\n",
    "    return\n",
    "def testspeaktofile(paragraphs,out):\n",
    "    print('loading model')\n",
    "    model = TTSModel(\"tts_model.pth.tar\",\"config.json\",\"vocoder_model.pth.tar\",\"config_vocoder.json\",False,False)\n",
    "    print('processing')\n",
    "    sents = preprocess(paragraphs)\n",
    "    print('test speaking')\n",
    "    sillyspeak(model, sents,out)\n",
    "    del model\n",
    "    print(\"Done!\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > num_mels:80\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:0\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:50.0\n",
      " | > mel_fmax:7600.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > stats_path:./scale_stats.npy\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Using model: Tacotron2\n",
      " > Generator Model: multiband_melgan_generator\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > num_mels:80\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:0\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:50.0\n",
      " | > mel_fmax:7600.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > stats_path:./scale_stats.npy\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      "processing\n",
      "test speaking\n",
      " > Run-time: 2.6999125480651855\n",
      " > Memory Used: 1071 MB\n",
      "Perhaps more faithful as blasphemy is faithful, than as reverent worship and identification.\n",
      " > Run-time: 2.1364901065826416\n",
      " > Memory Used: 1119 MB\n",
      "1\n",
      "Blasphemy has always seemed to require taking things very seriously.\n",
      " > Run-time: 1.0932674407958984\n",
      " > Memory Used: 1202 MB\n",
      "2\n",
      "I know no better stance to adopt from within the secular-religious, evangelical traditions of United States politics, including the politics of socialist feminism.\n",
      " > Run-time: 2.3314104080200195\n",
      " > Memory Used: 1420 MB\n",
      "3\n",
      "Blasphemy protects one from the moral majority within, while still insisting on the need for community.\n",
      " > Run-time: 1.5584118366241455\n",
      " > Memory Used: 1486 MB\n",
      "4\n",
      "Blasphemy is not apostasy.\n",
      " > Run-time: 0.6318211555480957\n",
      " > Memory Used: 1509 MB\n",
      "5\n",
      "Irony is about contradictions that do not resolve into larger wholes, even dialectically, about the tension of holding incompatible things together because both or all are necessary and true.\n",
      " > Run-time: 2.925168037414551\n",
      " > Memory Used: 1752 MB\n",
      "6\n",
      "Irony is about humour and serious play.\n",
      " > Run-time: 0.8447225093841553\n",
      " > Memory Used: 1752 MB\n",
      "7\n",
      "It is also a rhetorical strategy and a political method, one I would like to see more honoured within socialist-feminism.\n",
      " > Run-time: 2.0517666339874268\n",
      " > Memory Used: 1839 MB\n",
      "8\n",
      "At the centre of my ironic faith, my blasphemy, is the image of the cyborg.\n",
      " > Run-time: 1.4089818000793457\n",
      " > Memory Used: 1913 MB\n",
      "9\n",
      " A cyborg is a cybernetic organism, a hybrid of machine and organism, a creature of social reality as well as a creature of fiction.\n",
      " > Run-time: 2.686802387237549\n",
      " > Memory Used: 2147 MB\n",
      "10\n",
      "Social reality is lived social relations, our most important political construction, a world-changing fiction.\n",
      " > Run-time: 1.9968135356903076\n",
      " > Memory Used: 2224 MB\n",
      "11\n",
      "The international women's movements have constructed 'women's experience', as well as uncovered or discovered this crucial collective object.\n",
      " > Run-time: 2.2004964351654053\n",
      " > Memory Used: 2373 MB\n",
      "12\n",
      "This experience is a fiction and fact of the most crucial, political kind.\n",
      " > Run-time: 1.3778598308563232\n",
      " > Memory Used: 2427 MB\n",
      "13\n",
      "Liberation rests on the construction of the consciousness, the imaginative apprehension, of oppression, and so of possibility.\n",
      " > Run-time: 2.6962971687316895\n",
      " > Memory Used: 2586 MB\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7bfc72cd2ff5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#speaktofile(words,'manifesto.wav')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# option 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtestspeaktofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'manifesto.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-7628137b9e92>\u001b[0m in \u001b[0;36mtestspeaktofile\u001b[0;34m(paragraphs, out)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0msents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparagraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test speaking'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0msillyspeak\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-7628137b9e92>\u001b[0m in \u001b[0;36msillyspeak\u001b[0;34m(ttsmodel, sents, out)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mtmpmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0maccwavs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-7628137b9e92>\u001b[0m in \u001b[0;36maccwavs\u001b[0;34m(out, tmp)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0madd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pydub/audio_segment.py\u001b[0m in \u001b[0;36mfrom_wav\u001b[0;34m(cls, file, parameters)\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pydub/audio_segment.py\u001b[0m in \u001b[0;36mfrom_file\u001b[0;34m(cls, file, format, codec, parameters, **kwargs)\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m             \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmediainfo_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_ahead_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_ahead_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             audio_streams = [x for x in info['streams']\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pydub/utils.py\u001b[0m in \u001b[0;36mmediainfo_json\u001b[0;34m(filepath, read_ahead_limit)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprober\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-of'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'json'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcommand_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstdin_parameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstdin_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    798\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;31m# Cleanup if the child failed starting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1480\u001b[0m                             \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m                             \u001b[0merrpipe_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrpipe_write\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m                             restore_signals, start_new_session, preexec_fn)\n\u001b[0m\u001b[1;32m   1483\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_child_created\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "file = open(\"ACyborgManifesto\",\"r\")\n",
    "#words = file.readlines()\n",
    "#words = ' '.join(words[:5])\n",
    "words = file.read()\n",
    "file.close()\n",
    "del file\n",
    "#print(preprocess(words))\n",
    "# option 1\n",
    "#speaktofile(words,'manifesto.wav')\n",
    "# option 2\n",
    "testspeaktofile(words,'manifesto.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DDC-TTS_and_MultiBand-MelGAN_Example.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
